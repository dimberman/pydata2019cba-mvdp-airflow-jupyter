{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_estimators = 50\n",
    "datasets_root_path = '/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: full: (1309, 12) titanic: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(f'{datasets_root_path}/titanic/train.csv')\n",
    "test = pd.read_csv(f'{datasets_root_path}/titanic/test.csv')\n",
    "\n",
    "full = train.append( test , ignore_index = True, sort = False )\n",
    "titanic = full[ :891 ]\n",
    "\n",
    "del train , test\n",
    "\n",
    "print ('Datasets:' , 'full:' , full.shape , 'titanic:' , titanic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "sex = pd.Series( np.where( full.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\n",
    "embarked = pd.get_dummies( full.Embarked , prefix='Embarked' )\n",
    "pclass = pd.get_dummies( full.Pclass , prefix='Pclass' )\n",
    "\n",
    "### Fill missing values\n",
    "# Create dataset\n",
    "imputed = pd.DataFrame()\n",
    "imputed[ 'Age' ] = full.Age.fillna(full.Age.mean())\n",
    "imputed[ 'Fare' ] = full.Fare.fillna(full.Fare.mean())\n",
    "\n",
    "### Feature Engineering\n",
    "title = pd.DataFrame()\n",
    "# we extract the title from each name\n",
    "title[ 'Title' ] = full[ 'Name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
    "\n",
    "# a map of more aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                    }\n",
    "\n",
    "# we map each title\n",
    "title[ 'Title' ] = title.Title.map( Title_Dictionary )\n",
    "title = pd.get_dummies( title.Title )\n",
    "\n",
    "cabin = pd.DataFrame()\n",
    "# replacing missing cabins with U (for Uknown)\n",
    "cabin[ 'Cabin' ] = full.Cabin.fillna( 'U' )\n",
    "# mapping each Cabin value with the cabin letter\n",
    "cabin[ 'Cabin' ] = cabin[ 'Cabin' ].map( lambda c : c[0] )\n",
    "# dummy encoding ...\n",
    "cabin = pd.get_dummies( cabin['Cabin'] , prefix = 'Cabin' )\n",
    "\n",
    "def cleanTicket( ticket ):\n",
    "    ticket = ticket.replace( '.' , '' )\n",
    "    ticket = ticket.replace( '/' , '' )\n",
    "    ticket = ticket.split()\n",
    "    ticket = map( lambda t : t.strip() , ticket )\n",
    "    ticket = list(filter( lambda t : not t.isdigit() , ticket ))\n",
    "    if len( ticket ) > 0:\n",
    "        return ticket[0]\n",
    "    else: \n",
    "        return 'XXX'\n",
    "\n",
    "ticket = pd.DataFrame()\n",
    "# Extracting dummy variables from tickets:\n",
    "ticket[ 'Ticket' ] = full[ 'Ticket' ].map( cleanTicket )\n",
    "ticket = pd.get_dummies( ticket[ 'Ticket' ] , prefix = 'Ticket' )\n",
    "\n",
    "family = pd.DataFrame()\n",
    "# introducing a new feature : the size of families (including the passenger)\n",
    "family[ 'FamilySize' ] = full[ 'Parch' ] + full[ 'SibSp' ] + 1\n",
    "# introducing other features based on the family size\n",
    "family[ 'Family_Single' ] = family[ 'FamilySize' ].map( lambda s : 1 if s == 1 else 0 )\n",
    "family[ 'Family_Small' ]  = family[ 'FamilySize' ].map( lambda s : 1 if 2 <= s <= 4 else 0 )\n",
    "family[ 'Family_Large' ]  = family[ 'FamilySize' ].map( lambda s : 1 if 5 <= s else 0 )\n",
    "\n",
    "## Assemble final dataset\n",
    "full_X = pd.concat( [ imputed , embarked , cabin , sex ] , axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Create all datasets that are necessary to train, validate and test models\n",
    "train_valid_X = full_X[ 0:891 ]\n",
    "train_valid_y = titanic.Survived\n",
    "test_X = full_X[ 891: ]\n",
    "train_X , valid_X , train_y , valid_y = train_test_split( train_valid_X , train_valid_y , train_size = .7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( train_X , train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985553772070626 0.7910447761194029\n"
     ]
    }
   ],
   "source": [
    "print (model.score( train_X , train_y ) , model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "891          892       0.0\n",
       "892          893       0.0\n",
       "893          894       0.0\n",
       "894          895       1.0\n",
       "895          896       1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y = model.predict( test_X )\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y } )\n",
    "test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "test.to_csv( f'{datasets_root_path}/output/titanic_pred_{n_estimators}.csv' , index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/helgejo/an-interactive-data-science-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.1.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}